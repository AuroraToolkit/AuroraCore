<!DOCTYPE html>
<html lang="en">
  <head>
    <title>AuroraCore  Reference</title>
    <link rel="stylesheet" type="text/css" href="css/jazzy.css" />
    <link rel="stylesheet" type="text/css" href="css/highlight.css" />
    <meta charset='utf-8'>
    <script src="js/jquery.min.js" defer></script>
    <script src="js/jazzy.js" defer></script>
    
    <script src="js/lunr.min.js" defer></script>
    <script src="js/typeahead.jquery.js" defer></script>
    <script src="js/jazzy.search.js" defer></script>
  </head>
  <body>
    <a title="AuroraCore  Reference"></a>
    <header>
      <div class="content-wrapper">
        <p><a href="index.html">AuroraCore Docs</a> (93% documented)</p>
        <div class="header-right">
          <form role="search" action="search.json">
            <input type="text" placeholder="Search documentation" data-typeahead>
          </form>
        </div>
      </div>
    </header>
    <div class="content-wrapper">
      <p id="breadcrumbs">
        <a href="index.html">AuroraCore</a>
      </p>
    </div>
    <div class="content-wrapper">
      <nav class="sidebar">
        <ul class="nav-groups">
          <li class="nav-group-name">
            <a href="Classes.html">Classes</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Classes/AnthropicService.html">AnthropicService</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/ContextController.html">ContextController</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/ContextManager.html">ContextManager</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/CustomLogger.html">CustomLogger</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LLMDomainRouter.html">LLMDomainRouter</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LLMManager.html">LLMManager</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LLMManager/Routing.html">– Routing</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LLMServiceFactory.html">LLMServiceFactory</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LLMTask.html">LLMTask</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/LoadContextTask.html">LoadContextTask</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/OllamaService.html">OllamaService</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/OpenAIService.html">OpenAIService</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/RSSParsingTask.html">RSSParsingTask</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/SaveContextTask.html">SaveContextTask</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/SecureStorage.html">SecureStorage</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/SummarizeContextTask.html">SummarizeContextTask</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/SummarizeStringsTask.html">SummarizeStringsTask</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/Summarizer.html">Summarizer</a>
              </li>
              <li class="nav-group-task">
                <a href="Classes/TrimmingTask.html">TrimmingTask</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Enums.html">Enumerations</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Enums/LLMRole.html">LLMRole</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/LLMServiceError.html">LLMServiceError</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/SummaryType.html">SummaryType</a>
              </li>
              <li class="nav-group-task">
                <a href="Enums/TokenAdjustmentPolicy.html">TokenAdjustmentPolicy</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Extensions.html">Extensions</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Extensions/String.html">String</a>
              </li>
              <li class="nav-group-task">
                <a href="Extensions/String/TrimmingStrategy.html">– TrimmingStrategy</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Protocols.html">Protocols</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Protocols/LLMDomainRouterProtocol.html">LLMDomainRouterProtocol</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/LLMResponseProtocol.html">LLMResponseProtocol</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/LLMServiceProtocol.html">LLMServiceProtocol</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/SummarizerProtocol.html">SummarizerProtocol</a>
              </li>
              <li class="nav-group-task">
                <a href="Protocols/WorkflowComponent.html">WorkflowComponent</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="Structs.html">Structures</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="Structs/AnthropicLLMResponse.html">AnthropicLLMResponse</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/AnthropicLLMResponse.html#/s:10AuroraCore20AnthropicLLMResponseV7ContentV">– Content</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/AnthropicLLMResponse.html#/s:10AuroraCore20AnthropicLLMResponseV5UsageV">– Usage</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/AnthropicLLMStreamingResponse.html">AnthropicLLMStreamingResponse</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/AnthropicLLMStreamingResponse/Delta.html">– Delta</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/AnthropicLLMStreamingResponse/ContentBlock.html">– ContentBlock</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/AnthropicLLMStreamingResponse/Usage.html">– Usage</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/AnyWorkflowComponent.html">AnyWorkflowComponent</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Bookmark.html">Bookmark</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Context.html">Context</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/ContextItem.html">ContextItem</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/FetchContextsTask.html">FetchContextsTask</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/FetchURLTask.html">FetchURLTask</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/LLMMessage.html">LLMMessage</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/LLMRequest.html">LLMRequest</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/LLMRequestOptions.html">LLMRequestOptions</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/LLMTokenUsage.html">LLMTokenUsage</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/OllamaLLMResponse.html">OllamaLLMResponse</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/OpenAILLMResponse.html">OpenAILLMResponse</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/OpenAILLMResponse/Choice.html">– Choice</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/OpenAILLMResponse.html#/s:10AuroraCore17OpenAILLMResponseV5UsageV">– Usage</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/RSSArticle.html">RSSArticle</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/SummarizerOptions.html">SummarizerOptions</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Workflow.html">Workflow</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Workflow/State.html">– State</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Workflow/Component.html">– Component</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Workflow/Task.html">– Task</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/Workflow/TaskGroup.html">– TaskGroup</a>
              </li>
              <li class="nav-group-task">
                <a href="Structs/WorkflowBuilder.html">WorkflowBuilder</a>
              </li>
            </ul>
          </li>
        </ul>
      </nav>
      <article class="main-content">
        <section>
          <section class="section">
            
            <h1 id='auroracore' class='heading'>AuroraCore</h1>

<p>AuroraCore is the foundational library within the AuroraToolkit—a suite of tools designed to simplify the integration of AI capabilities into your projects. This package provides robust support for AI-driven workflows, including context management, task orchestration, and seamless integrations with large language models (LLMs) from organizations such as Anthropic, OpenAI, and Ollama. Its modular architecture empowers developers to customize, extend, and integrate with external services effortlessly.</p>
<h2 id='features' class='heading'>Features</h2>

<ul>
<li><strong>Context Management</strong>: Handle and maintain conversation or task-specific context, including adding, retrieving, and summarizing items.</li>
<li><strong>Task and Workflow Handling</strong>: Built-in support for defining and managing tasks and workflows, supporting asynchronous task execution for handling complex, long-running tasks.</li>
<li><strong>Declarative Workflow syntax</strong>: Define workflows declaratively, similar to SwiftUI for UI.</li>
<li><strong>LLM Integration</strong>: Seamless integration with various LLM services via an extendable <code><a href="Classes/LLMManager.html">LLMManager</a></code>. Supports token management, trimming strategies, domain-routing, and fallback mechanisms.</li>
<li><strong>Domain-Specific Routing</strong>: Route requests to the most appropriate LLM service based on predefined domains or fallback options, enabling modular and efficient service management.</li>
<li><strong>Examples for Quick Start</strong>: Includes ready-to-run examples demonstrating common patterns like domain-specific routing and fallback handling.</li>
<li><strong>Modular and Extendable</strong>: AuroraCore is designed to be modular, allowing developers to plug in their own services, workflows, or task managers.</li>
</ul>
<h2 id='major-components' class='heading'>Major Components</h2>
<h3 id='1-strong-contextcontroller-strong' class='heading'>1. <strong>ContextController</strong></h3>

<p>The <code><a href="Classes/ContextController.html">ContextController</a></code> manages context data, including adding, updating, and summarizing items. It works closely with summarizers and handles context tokenization.</p>
<h3 id='2-strong-llmmanager-strong' class='heading'>2. <strong>LLMManager</strong></h3>

<p>The <code><a href="Classes/LLMManager.html">LLMManager</a></code> is responsible for managing connections to various language model services, handling requests, and managing token limits. It supports trimming strategies (start, middle, end) to fit within LLM token limits.</p>
<h3 id='3-strong-contextmanager-strong' class='heading'>3. <strong>ContextManager</strong></h3>

<p><code><a href="Classes/ContextManager.html">ContextManager</a></code> supervises multiple <code><a href="Classes/ContextController.html">ContextController</a></code> instances, allowing for the management of multiple contexts. It handles saving and loading contexts to disk, as well as setting the active context.</p>
<h3 id='4-strong-workflow-strong' class='heading'>4. <strong>Workflow</strong></h3>

<p>The <code><a href="Structs/Workflow.html">Workflow</a></code> provide declarative mechanisms to define tasks and task groups, to execute complex workflows. It supports asynchronous task execution, making it suitable for workflows involving AI, network requests, and other asynchronous tasks.</p>
<h2 id='installation' class='heading'>Installation</h2>
<h3 id='swift-package-manager' class='heading'>Swift Package Manager</h3>

<p>To integrate AuroraCore into your project using Swift Package Manager, add the following line to your <code>Package.swift</code> file:</p>
<pre class="highlight swift"><code><span class="o">.</span><span class="nf">package</span><span class="p">(</span><span class="nv">url</span><span class="p">:</span> <span class="s">"https://github.com/AuroraToolkit/AuroraCore.git"</span><span class="p">,</span> <span class="nv">from</span><span class="p">:</span> <span class="s">"0.1.0"</span><span class="p">)</span>
</code></pre>

<p>Then add <code>AuroraCore</code> as a dependency to your target:</p>
<pre class="highlight swift"><code><span class="o">.</span><span class="nf">target</span><span class="p">(</span>
    <span class="nv">name</span><span class="p">:</span> <span class="s">"YourTarget"</span><span class="p">,</span>
    <span class="nv">dependencies</span><span class="p">:</span> <span class="p">[</span><span class="s">"AuroraCore"</span><span class="p">]),</span>
</code></pre>
<h2 id='usage' class='heading'>Usage</h2>
<h3 id='setting-up-a-context' class='heading'>Setting up a Context</h3>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">AuroraCore</span>

<span class="k">let</span> <span class="nv">contextController</span> <span class="o">=</span> <span class="kt">ContextController</span><span class="p">(</span><span class="nv">maxTokenLimit</span><span class="p">:</span> <span class="mi">4096</span><span class="p">)</span>
<span class="n">contextController</span><span class="o">.</span><span class="nf">addItem</span><span class="p">(</span><span class="nv">content</span><span class="p">:</span> <span class="s">"This is a new item."</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">summary</span> <span class="o">=</span> <span class="n">contextController</span><span class="o">.</span><span class="nf">summarizeContext</span><span class="p">()</span>
</code></pre>
<h3 id='using-workflows-and-tasks' class='heading'>Using Workflows and Tasks</h3>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">AuroraCore</span>

<span class="k">let</span> <span class="nv">workflow</span> <span class="o">=</span> <span class="kt">Workflow</span><span class="p">(</span><span class="nv">name</span><span class="p">:</span> <span class="s">"Example Workflow"</span><span class="p">,</span> <span class="nv">description</span><span class="p">:</span> <span class="s">"This is a sample workflow"</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">Workflow</span><span class="o">.</span><span class="kt">Task</span><span class="p">(</span><span class="nv">name</span><span class="p">:</span> <span class="s">"Task_1"</span><span class="p">,</span> <span class="nv">description</span><span class="p">:</span> <span class="s">"This is the first task."</span><span class="p">)</span>
    <span class="kt">Workflow</span><span class="o">.</span><span class="kt">Task</span><span class="p">(</span><span class="nv">name</span><span class="p">:</span> <span class="s">"Task_2"</span><span class="p">,</span> <span class="nv">description</span><span class="p">:</span> <span class="s">"This is the second task."</span><span class="p">)</span> <span class="p">{</span> <span class="n">inputs</span> <span class="k">in</span>
        <span class="c1">// Perform some task-specific logic</span>
        <span class="k">return</span> <span class="p">[</span><span class="s">"result"</span><span class="p">:</span> <span class="s">"Task 2 completed."</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">await</span> <span class="n">workflow</span><span class="o">.</span><span class="nf">start</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="s">"Workflow completed. Result: </span><span class="se">\(</span><span class="n">workflow</span><span class="o">.</span><span class="n">outputs</span><span class="p">[</span><span class="s">"Task_2.result"</span><span class="p">]</span> <span class="k">as?</span> <span class="kt">String</span><span class="se">)</span><span class="s">"</span><span class="p">)</span>
</code></pre>
<h3 id='llm-integration' class='heading'>LLM Integration</h3>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">AuroraCore</span>

<span class="k">let</span> <span class="nv">llmManager</span> <span class="o">=</span> <span class="kt">LLMManager</span><span class="p">()</span>
<span class="n">llmManager</span><span class="o">.</span><span class="nf">registerService</span><span class="p">(</span><span class="kt">OllamaService</span><span class="p">(</span><span class="nv">name</span><span class="p">:</span> <span class="s">"Ollama"</span><span class="p">))</span>

<span class="k">let</span> <span class="nv">request</span> <span class="o">=</span> <span class="kt">LLMRequest</span><span class="p">(</span><span class="nv">prompt</span><span class="p">:</span> <span class="s">"Hello, World!"</span><span class="p">)</span>
<span class="n">llmManager</span><span class="o">.</span><span class="nf">sendRequest</span><span class="p">(</span><span class="n">request</span><span class="p">)</span> <span class="p">{</span> <span class="n">response</span> <span class="k">in</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">response</span><span class="p">?</span><span class="o">.</span><span class="n">text</span> <span class="p">??</span> <span class="s">"No response"</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
<h3 id='domain-specific-routing-with-llmmanager' class='heading'>Domain-specific Routing with LLMManager</h3>
<pre class="highlight swift"><code><span class="kd">import</span> <span class="kt">AuroraCore</span>

<span class="k">let</span> <span class="nv">manager</span> <span class="o">=</span> <span class="kt">LLMManager</span><span class="p">()</span>

<span class="c1">// Configure the Domain Routing Service (Ollama)</span>
<span class="k">let</span> <span class="nv">router</span> <span class="o">=</span> <span class="kt">LLMDomainRouter</span><span class="p">(</span>
    <span class="nv">name</span><span class="p">:</span> <span class="s">"Domain Router"</span><span class="p">,</span>
    <span class="nv">service</span><span class="p">:</span> <span class="kt">OllamaService</span><span class="p">(),</span>
    <span class="nv">supportedDomains</span><span class="p">:</span> <span class="p">[</span><span class="s">"sports"</span><span class="p">,</span> <span class="s">"movies"</span><span class="p">,</span> <span class="s">"books"</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">manager</span><span class="o">.</span><span class="nf">registerDomainRouter</span><span class="p">(</span><span class="n">router</span><span class="p">)</span>

<span class="c1">// Configure the Sports Service (Anthropic)</span>
<span class="k">let</span> <span class="nv">sportsService</span> <span class="o">=</span> <span class="kt">AnthropicService</span><span class="p">(</span>
    <span class="nv">name</span><span class="p">:</span> <span class="s">"SportsService"</span><span class="p">,</span>
    <span class="nv">apiKey</span><span class="p">:</span> <span class="s">"your-anthropic-api-key"</span><span class="p">,</span>
    <span class="nv">maxOutputTokens</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="nv">systemPrompt</span><span class="p">:</span> <span class="s">"""
You are a sports expert. Answer the following sports-related questions concisely and accurately.
"""</span>
<span class="p">)</span>
<span class="n">manager</span><span class="o">.</span><span class="nf">registerService</span><span class="p">(</span><span class="n">sportsService</span><span class="p">,</span> <span class="nv">withRoutings</span><span class="p">:</span> <span class="p">[</span><span class="o">.</span><span class="nf">domain</span><span class="p">([</span><span class="s">"sports"</span><span class="p">])])</span>

<span class="c1">// Configure the Movies Service (OpenAI)</span>
<span class="k">let</span> <span class="nv">moviesService</span> <span class="o">=</span> <span class="kt">OpenAIService</span><span class="p">(</span>
    <span class="nv">name</span><span class="p">:</span> <span class="s">"MoviesService"</span><span class="p">,</span>
    <span class="nv">apiKey</span><span class="p">:</span> <span class="s">"your-openai-api-key"</span><span class="p">,</span>
    <span class="nv">maxOutputTokens</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="nv">systemPrompt</span><span class="p">:</span> <span class="s">"""
You are a movie critic. Answer the following movie-related questions concisely and accurately.
"""</span>
<span class="p">)</span>
<span class="n">manager</span><span class="o">.</span><span class="nf">registerService</span><span class="p">(</span><span class="n">moviesService</span><span class="p">,</span> <span class="nv">withRoutings</span><span class="p">:</span> <span class="p">[</span><span class="o">.</span><span class="nf">domain</span><span class="p">([</span><span class="s">"movies"</span><span class="p">])])</span>

<span class="c1">// Configure the Books Service (Ollama)</span>
<span class="k">let</span> <span class="nv">booksService</span> <span class="o">=</span> <span class="kt">OllamaService</span><span class="p">(</span>
    <span class="nv">name</span><span class="p">:</span> <span class="s">"BooksService"</span><span class="p">,</span>
    <span class="nv">baseURL</span><span class="p">:</span> <span class="s">"http://localhost:11434"</span><span class="p">,</span>
    <span class="nv">maxOutputTokens</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="nv">systemPrompt</span><span class="p">:</span> <span class="s">"""
You are a literary expert. Answer the following books-related questions concisely and accurately.
"""</span>
<span class="p">)</span>
<span class="n">manager</span><span class="o">.</span><span class="nf">registerService</span><span class="p">(</span><span class="n">booksService</span><span class="p">,</span> <span class="nv">withRoutings</span><span class="p">:</span> <span class="p">[</span><span class="o">.</span><span class="nf">domain</span><span class="p">([</span><span class="s">"books"</span><span class="p">])])</span>

<span class="c1">// Configure the Fallback Service (OpenAI)</span>
<span class="k">let</span> <span class="nv">fallbackService</span> <span class="o">=</span> <span class="kt">OpenAIService</span><span class="p">(</span>
    <span class="nv">name</span><span class="p">:</span> <span class="s">"FallbackService"</span><span class="p">,</span>
    <span class="nv">apiKey</span><span class="p">:</span> <span class="s">"your-openai-api-key"</span><span class="p">,</span>
    <span class="nv">maxOutputTokens</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
    <span class="nv">systemPrompt</span><span class="p">:</span> <span class="s">"""
You are a helpful assistant. Answer any general questions accurately and concisely.
"""</span>
<span class="p">)</span>
<span class="n">manager</span><span class="o">.</span><span class="nf">registerFallbackService</span><span class="p">(</span><span class="n">fallbackService</span><span class="p">)</span>

<span class="c1">// Example questions</span>
<span class="k">let</span> <span class="nv">questions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"Who won the Super Bowl in 2022?"</span><span class="p">,</span>  <span class="c1">// Sports domain</span>
    <span class="s">"What won Best Picture in 2021?"</span><span class="p">,</span>   <span class="c1">// Movies domain</span>
    <span class="s">"Who wrote The Great Gatsby?"</span><span class="p">,</span>      <span class="c1">// Books domain</span>
    <span class="s">"What is the capital of France?"</span>    <span class="c1">// General (fallback)</span>
<span class="p">]</span>

<span class="c1">// Process each question</span>
<span class="k">for</span> <span class="n">question</span> <span class="k">in</span> <span class="n">questions</span> <span class="p">{</span>
    <span class="nf">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Processing question: </span><span class="se">\(</span><span class="n">question</span><span class="se">)</span><span class="s">"</span><span class="p">)</span>

    <span class="k">let</span> <span class="nv">request</span> <span class="o">=</span> <span class="kt">LLMRequest</span><span class="p">(</span><span class="nv">messages</span><span class="p">:</span> <span class="p">[</span><span class="kt">LLMMessage</span><span class="p">(</span><span class="nv">role</span><span class="p">:</span> <span class="o">.</span><span class="n">user</span><span class="p">,</span> <span class="nv">content</span><span class="p">:</span> <span class="n">question</span><span class="p">)])</span>

    <span class="k">if</span> <span class="k">let</span> <span class="nv">response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">manager</span><span class="o">.</span><span class="nf">routeRequest</span><span class="p">(</span><span class="n">request</span><span class="p">)</span> <span class="p">{</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"Response from </span><span class="se">\(</span><span class="n">response</span><span class="o">.</span><span class="n">vendor</span> <span class="p">??</span> <span class="s">"Uknown"</span><span class="se">)</span><span class="s">: </span><span class="se">\(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="se">)</span><span class="s">"</span><span class="p">)</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"No response received."</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre>
<h2 id='running-tests' class='heading'>Running Tests</h2>

<p>AuroraCore includes tests for multiple language model services. The Ollama tests will always run, as they do not require any API keys. For testing OpenAI or Anthropic services, you will need to manually provide your API keys.</p>
<h3 id='adding-api-keys-for-openai-and-anthropic' class='heading'>Adding API Keys for OpenAI and Anthropic:</h3>

<p>Some test and example files use OpenAI or Anthropic services and need API keys to function correctly. To use these services, add the following keys to the <code>AuroraCore</code> and <code>Examples</code> schemes. Make sure these schemes are not shared, and take extra precaution to avoid committing API keys into the repository.</p>

<ul>
<li>For Anthropic, add the environment variable <code>ANTHROPIC_API_KEY</code> with a valid test API key.</li>
<li>For OpenAI, add the environment variable <code>OPENAI_API_KEY</code> with a valid test API key.</li>
<li>Ollama does not require API keys, but does require the Ollama service to be running at the default service URL, <code>http://localhost:11434</code>.</li>
</ul>
<h3 id='important' class='heading'>Important:</h3>

<ul>
<li><strong>Never commit your API keys to the repository</strong>. The tests are designed to run with Ollama by default, and you can enable additional tests for OpenAI and Anthropic by manually adding your keys for local testing.</li>
<li>Be sure to remove or replace your keys with empty strings before committing any changes.</li>
</ul>

<p>With this setup, you can run the tests on multiple LLMs and ensure your sensitive keys are not inadvertently shared.</p>
<h2 id='future-ideas' class='heading'>Future Ideas</h2>

<ul>
<li><strong>On-device LLM support</strong>: Integrate with on-device language models to enable fast, private, and offline AI capabilities.</li>
<li><strong>Google LLM support</strong>: Support Gemini and future Google-built language models.</li>
<li><strong>Multimodal LLM support</strong>: Enable multimodal LLMs for use cases beyond plain text.</li>
<li><strong>Advanced Workflow features</strong>: Include dynamic task execution, prebuilt workflow templates for common AI tasks (e.g., summarization, Q&amp;A, data extraction) to jumpstart development.</li>
<li><strong>Time-based triggers</strong>: Automate workflows to execute at scheduled intervals or in response to real-world events for monitoring and alerting systems.</li>
</ul>
<h2 id='contributing' class='heading'>Contributing</h2>

<p>Contributions are welcome! Please feel free to submit a pull request or open an issue. For more details on how to contribute, please refer to the <a href="CONTRIBUTING.md">CONTRIBUTING.md</a> file.</p>
<h2 id='code-of-conduct' class='heading'>Code of Conduct</h2>

<p>We expect all participants to adhere to our <a href="CODE_OF_CONDUCT.md">Code of Conduct</a> to ensure a welcoming and inclusive environment for everyone.</p>
<h2 id='license' class='heading'>License</h2>

<p>AuroraCore is released under the <a href="LICENSE">Apache 2.0 License</a>.</p>
<h2 id='contact' class='heading'>Contact</h2>

<p>For any inquiries or feedback, please reach out to us at <a href="mailto:aurora.toolkit@gmail.com">aurora.toolkit@gmail.com</a>.</p>

          </section>
        </section>
        <section id="footer">
          <p>&copy; 2024 <a class="link" href="" target="_blank" rel="external noopener"></a>. All rights reserved. (Last updated: 2024-12-20)</p>
          <p>Generated by <a class="link" href="https://github.com/realm/jazzy" target="_blank" rel="external noopener">jazzy ♪♫ v0.15.1</a>, a <a class="link" href="https://realm.io" target="_blank" rel="external noopener">Realm</a> project.</p>
        </section>
      </article>
    </div>
  </body>
</html>
